<h1 align="center">
     <br>Self-Supervised Chain-of-Thought Learning for Test-Time Reasoning Enhancement in LLMs

<h4 align="center"></a>


## üî® Training

All datasets and their contents from AdaptEval are defined in the `dataset_info.json` file included in this repository. You only need to specify the desired dataset in your configuration file to use it.

For example, to adapt to the geography dataset:
- For offline test-time learning, you can start training with the following command:
```bash
CUDA_VISIBLE_DEVICES=0 llamafactory-cli train examples/train_lora/offline_ttl.yaml
```
- For online test-time learning, use:
```bash
CUDA_VISIBLE_DEVICES=0 llamafactory-cli train examples/train_lora/online_ttl.yaml
```
The `offline_ttl.yaml` and `online_ttl.yaml` files provide example configurations for fine-tuning with test-time learning. These configurations specify parameters about model, fine-tuning method, dataset, TTL method and so on. Please customize these files according to your own requirements.

## ‚öñÔ∏è Evaluation

After running the above training commands, you will obtain the model inference results in the specified `output_dir`. You can then evaluate these results.

First, install the required dependencies:
```bash
pip install rouge_score rouge-chinese bert_score git+https://github.com/google-research/bleurt.git
```
All evaluation-related scripts are located in the `scripts/eval` folder:
- For datasets in DomainBench and InstructionBench, copy the path to your model inference results into `eval_simility.py` and run the script.
- For datasets in ReasoningBench, copy the path to your model inference results into `eval_accuracy.py` and run the script.

## üí¨ Citation
Thanks for the open-source code of [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)

If you find our work interesting and meaningful, welcome to give a üåü to our repo and cite our paper.

```text
@inproceedings{hutest,
  title={Test-Time Learning for Large Language Models},
  author={Hu, Jinwu and Zhang, Zitian and Chen, Guohao and Wen, Xutao and Shuai, Chao and Luo, Wei and Xiao, Bin and Li, Yuanqing and Tan, Mingkui},
  booktitle={Forty-second International Conference on Machine Learning}
}
```

## Star History

![Star History Chart](https://api.star-history.com/svg?repos=Fhujinwu/TLM&type=Date)
